{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比赛标题\n",
    "Exp6: 基于集成学习的 Amazon 用户评论质量预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比赛描述\n",
    "\n",
    "本案例中我们将基于集成学习的方法对 Amazon 现实场景中的评论质量进行预测。需要大家完成两种集成学习算法的实现（Bagging、AdaBoost.M1），其中基分类器使用 SVM 和决策树两种，对结果进行对比分析。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比赛介绍\n",
    "\n",
    "### 案例背景\n",
    "\n",
    "随着电商平台的兴起，以及疫情的持续影响，线上购物在我们的日常生活中扮演着越来越重要的角色。在进行线上商品挑选时，评论往往是我们十分关注的一个方面。然而目前电商网站的评论质量参差不齐，甚至有水军刷好评或者恶意差评的情况出现，严重影响了顾客的购物体验。因此，对于评论质量的预测成为电商平台越来越关注的话题，如果能自动对评论质量进行评估，就能根据预测结果避免展现低质量的评论。本案例中我们将基于集成学习的方法对 Amazon 现实场景中的评论质量进行预测。\n",
    "\n",
    "### 任务\n",
    "\n",
    "本案例中需要完成两种集成学习算法的实现（Bagging、AdaBoost.M1），其中基分类器要求使用 SVM 和决策树两种，因此，一共需要对比四组结果（[AUC](https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics) 作为评价指标）：\n",
    "\n",
    "* Bagging + SVM\n",
    "* Bagging + 决策树\n",
    "* AdaBoost.M1 + SVM\n",
    "* AdaBoost.M1 + 决策树\n",
    "\n",
    "注意集成学习的核心算法需要**手动进行实现**，基分类器可以调库。\n",
    "\n",
    "### 基本要求\n",
    "\n",
    "* 根据数据格式设计特征的表示\n",
    "* 汇报不同组合下得到的 AUC\n",
    "* 结合不同集成学习算法的特点分析结果之间的差异\n",
    "* （使用 sklearn 等第三方库的集成学习算法会酌情扣分）\n",
    "\n",
    "### 扩展要求\n",
    "\n",
    "* 尝试其他基分类器（如 k-NN、朴素贝叶斯）\n",
    "* 分析不同特征的影响\n",
    "* 分析集成学习算法参数的影响\n",
    "* 尝试各种方法提升排行榜上预测性能\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 赛题说明\n",
    "### 数据描述\n",
    "\n",
    "本次数据来源于 Amazon 电商平台，包含超过 50,000 条用户在购买商品后留下的评论，各列的含义如下：\n",
    "\n",
    "* reviewerID：用户 ID\n",
    "* asin：商品 ID\n",
    "* reviewText：英文评论文本\n",
    "* overall：用户对商品的打分（1-5）\n",
    "* votes_up：认为评论有用的点赞数（只在训练集出现）\n",
    "* votes_all：该评论得到的总评价数（只在训练集出现）\n",
    "* label：评论质量的 label，1 表示高质量，0 表示低质量（只在训练集出现）\n",
    "\n",
    "评论质量的 label 来自于其他用户对评论的 votes，votes_up/votes_all ≥ 0.9 的作为高质量评论。此外测试集包含一个额外的列`Id`，标识了每一个测试的样例。\n",
    "\n",
    "### 文件说明\n",
    "\n",
    "* train.csv：训练集\n",
    "* test.csv：测试集，用户和商品保证在训练集中出现过，没有关于 votes 和 label 的列\n",
    "\n",
    "文件使用 \\t 分隔，可以使用 pandas 进行读取：\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv('train.csv', sep='\\t')\n",
    "```\n",
    "\n",
    "### 提交格式\n",
    "\n",
    "提交文件需要对测试集中每一条评论给出预测为高质量的**概率**，每行包括一个`Id`（和测试集对应）以及预测的概率`Predicted`（0-1的浮点数），用逗号分隔。示例提交格式如下：\n",
    "\n",
    "```\n",
    "Id,Predicted\n",
    "0,0.9\n",
    "1,0.45\n",
    "2,0.78\n",
    "...\n",
    "```\n",
    "\n",
    "提交文件需要命名为`result.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_all</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7885</td>\n",
       "      <td>3901</td>\n",
       "      <td>First off, allow me to correct a common mistak...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52087</td>\n",
       "      <td>47978</td>\n",
       "      <td>I am really troubled by this Story and Enterta...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5701</td>\n",
       "      <td>3667</td>\n",
       "      <td>A near-perfect film version of a downright glo...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47191</td>\n",
       "      <td>40892</td>\n",
       "      <td>Keep your expectations low.  Really really low...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40957</td>\n",
       "      <td>15367</td>\n",
       "      <td>\"they dont make em like this no more...\"well.....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57034</th>\n",
       "      <td>58315</td>\n",
       "      <td>29374</td>\n",
       "      <td>If you like beautifully shot, well acted films...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57035</th>\n",
       "      <td>23328</td>\n",
       "      <td>45548</td>\n",
       "      <td>This is a great set of films Wayne did Fox and...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57036</th>\n",
       "      <td>27203</td>\n",
       "      <td>42453</td>\n",
       "      <td>It's what's known as a comedy of manners. It's...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57037</th>\n",
       "      <td>33992</td>\n",
       "      <td>44891</td>\n",
       "      <td>Ellen can do no wrong as far a creating wonder...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57038</th>\n",
       "      <td>27478</td>\n",
       "      <td>19198</td>\n",
       "      <td>I agree with everyone else that this is a grea...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57039 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID   asin                                         reviewText  \\\n",
       "0            7885   3901  First off, allow me to correct a common mistak...   \n",
       "1           52087  47978  I am really troubled by this Story and Enterta...   \n",
       "2            5701   3667  A near-perfect film version of a downright glo...   \n",
       "3           47191  40892  Keep your expectations low.  Really really low...   \n",
       "4           40957  15367  \"they dont make em like this no more...\"well.....   \n",
       "...           ...    ...                                                ...   \n",
       "57034       58315  29374  If you like beautifully shot, well acted films...   \n",
       "57035       23328  45548  This is a great set of films Wayne did Fox and...   \n",
       "57036       27203  42453  It's what's known as a comedy of manners. It's...   \n",
       "57037       33992  44891  Ellen can do no wrong as far a creating wonder...   \n",
       "57038       27478  19198  I agree with everyone else that this is a grea...   \n",
       "\n",
       "       overall  votes_up  votes_all  label  \n",
       "0          5.0         6          7      0  \n",
       "1          3.0        99        134      0  \n",
       "2          4.0        14         14      1  \n",
       "3          1.0         4          7      0  \n",
       "4          5.0         3          6      0  \n",
       "...        ...       ...        ...    ...  \n",
       "57034      2.0        12         21      0  \n",
       "57035      5.0        15         18      0  \n",
       "57036      3.0         4          5      0  \n",
       "57037      5.0         4          5      0  \n",
       "57038      2.0         5          5      1  \n",
       "\n",
       "[57039 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data\\\\train.csv', sep='\\t')\n",
    "test_df = pd.read_csv('data\\\\test.csv', sep='\\t')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>82947</td>\n",
       "      <td>37386</td>\n",
       "      <td>I REALLY wanted this series but I am in SHOCK ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10154</td>\n",
       "      <td>23543</td>\n",
       "      <td>I have to say that this is a work of art for m...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5789</td>\n",
       "      <td>5724</td>\n",
       "      <td>Alien 3 is certainly the most controversal fil...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9198</td>\n",
       "      <td>5909</td>\n",
       "      <td>I love this film...preachy?  Well, of course i...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>33252</td>\n",
       "      <td>21214</td>\n",
       "      <td>Even though I previously bought the Gamera Dou...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11203</th>\n",
       "      <td>11203</td>\n",
       "      <td>18250</td>\n",
       "      <td>35309</td>\n",
       "      <td>I honestly never heard of the graphic novel un...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11204</th>\n",
       "      <td>11204</td>\n",
       "      <td>3200</td>\n",
       "      <td>2130</td>\n",
       "      <td>Archie Bunker's command to stifle YOURSELF! wa...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11205</th>\n",
       "      <td>11205</td>\n",
       "      <td>37366</td>\n",
       "      <td>41971</td>\n",
       "      <td>In LSD - My Problem Child, Albert Hoffman wrot...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11206</th>\n",
       "      <td>11206</td>\n",
       "      <td>1781</td>\n",
       "      <td>33089</td>\n",
       "      <td>I have owned this DVD for over a year now and ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11207</th>\n",
       "      <td>11207</td>\n",
       "      <td>26372</td>\n",
       "      <td>35457</td>\n",
       "      <td>This movie is just a slap in the face [or othe...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11208 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  reviewerID   asin  \\\n",
       "0          0       82947  37386   \n",
       "1          1       10154  23543   \n",
       "2          2        5789   5724   \n",
       "3          3        9198   5909   \n",
       "4          4       33252  21214   \n",
       "...      ...         ...    ...   \n",
       "11203  11203       18250  35309   \n",
       "11204  11204        3200   2130   \n",
       "11205  11205       37366  41971   \n",
       "11206  11206        1781  33089   \n",
       "11207  11207       26372  35457   \n",
       "\n",
       "                                              reviewText  overall  \n",
       "0      I REALLY wanted this series but I am in SHOCK ...      1.0  \n",
       "1      I have to say that this is a work of art for m...      4.0  \n",
       "2      Alien 3 is certainly the most controversal fil...      3.0  \n",
       "3      I love this film...preachy?  Well, of course i...      5.0  \n",
       "4      Even though I previously bought the Gamera Dou...      5.0  \n",
       "...                                                  ...      ...  \n",
       "11203  I honestly never heard of the graphic novel un...      5.0  \n",
       "11204  Archie Bunker's command to stifle YOURSELF! wa...      5.0  \n",
       "11205  In LSD - My Problem Child, Albert Hoffman wrot...      5.0  \n",
       "11206  I have owned this DVD for over a year now and ...      5.0  \n",
       "11207  This movie is just a slap in the face [or othe...      1.0  \n",
       "\n",
       "[11208 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_all</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33359.761865</td>\n",
       "      <td>19973.170866</td>\n",
       "      <td>3.535178</td>\n",
       "      <td>12.387594</td>\n",
       "      <td>18.475850</td>\n",
       "      <td>0.226196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30016.804127</td>\n",
       "      <td>14104.410152</td>\n",
       "      <td>1.529742</td>\n",
       "      <td>45.130499</td>\n",
       "      <td>50.149683</td>\n",
       "      <td>0.418371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9235.000000</td>\n",
       "      <td>8218.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22589.000000</td>\n",
       "      <td>17635.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53170.000000</td>\n",
       "      <td>30875.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>123767.000000</td>\n",
       "      <td>50051.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6084.000000</td>\n",
       "      <td>6510.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reviewerID          asin       overall      votes_up     votes_all  \\\n",
       "count   57039.000000  57039.000000  57039.000000  57039.000000  57039.000000   \n",
       "mean    33359.761865  19973.170866      3.535178     12.387594     18.475850   \n",
       "std     30016.804127  14104.410152      1.529742     45.130499     50.149683   \n",
       "min        50.000000      0.000000      1.000000      0.000000      5.000000   \n",
       "25%      9235.000000   8218.000000      2.000000      4.000000      6.000000   \n",
       "50%     22589.000000  17635.000000      4.000000      6.000000     10.000000   \n",
       "75%     53170.000000  30875.000000      5.000000     11.000000     18.000000   \n",
       "max    123767.000000  50051.000000      5.000000   6084.000000   6510.000000   \n",
       "\n",
       "              label  \n",
       "count  57039.000000  \n",
       "mean       0.226196  \n",
       "std        0.418371  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#为了避免过拟合，将ID等特征分为20类，并投影到[0,1]上\n",
    "\n",
    "discrete_train_df = train_df.copy()\n",
    "discrete_train_df['asin'] = pd.cut(discrete_train_df['asin'], bins = 20,labels = False)\n",
    "discrete_train_df['reviewerID'] = pd.cut(discrete_train_df['reviewerID'], bins = 20,labels = False)\n",
    "discrete_train_df['asin'] = discrete_train_df['asin'] / max(discrete_train_df['asin'])\n",
    "discrete_train_df['reviewerID'] = discrete_train_df['reviewerID'] / discrete_train_df['reviewerID'].max()\n",
    "discrete_train_df['overall'] = discrete_train_df['overall'] / 5.0\n",
    "\n",
    "\n",
    "discrete_test_df = test_df.copy()\n",
    "discrete_test_df['asin'] = pd.cut(discrete_test_df['asin'], bins = 20,labels = False)\n",
    "discrete_test_df['reviewerID'] = pd.cut(discrete_test_df['reviewerID'], bins = 20,labels = False)\n",
    "discrete_test_df['asin'] = discrete_test_df['asin'] / discrete_test_df['asin'].max()\n",
    "discrete_test_df['reviewerID'] = discrete_test_df['reviewerID'] / discrete_test_df['reviewerID'].max()\n",
    "discrete_test_df['overall'] = discrete_test_df['overall'] / 5.0\n",
    "\n",
    "\n",
    "\n",
    "# discreteAsin =  np.floor(train_df['asin'] / 2000)\n",
    "# discreteAsin =  discreteAsin / max(discreteAsin)\n",
    "# discreteID = np.floor(train_df['reviewerID'] / 5000)\n",
    "# discreteID = discreteID / max(discreteID)\n",
    "# discreteOverall = train_df['overall'] / 5\n",
    "\n",
    "# test_discreteAsin =  np.floor(test_df['asin'] / 2000)\n",
    "# test_discreteAsin =  test_discreteAsin / max(test_discreteAsin)\n",
    "# test_discreteID = np.floor(test_df['reviewerID'] / 5000)\n",
    "# test_discreteID = test_discreteID / max(test_discreteID)\n",
    "# test_discreteOverall = test_df['overall'] / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.052632\n",
       "1        1.000000\n",
       "2        0.052632\n",
       "3        0.842105\n",
       "4        0.315789\n",
       "           ...   \n",
       "57034    0.578947\n",
       "57035    0.947368\n",
       "57036    0.842105\n",
       "57037    0.894737\n",
       "57038    0.368421\n",
       "Name: asin, Length: 57039, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_train_df['asin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2063.,    0., 1327.,    0., 1366.,    0.,    0., 1850.,    0.,\n",
       "        4602.]),\n",
       " array([0.2 , 0.28, 0.36, 0.44, 0.52, 0.6 , 0.68, 0.76, 0.84, 0.92, 1.  ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, axes = plt.subplots(1, 3, figsize = (16,5))\n",
    "axes[0].hist(discrete_train_df['asin'], alpha = 0.5)\n",
    "axes[0].hist(discrete_test_df['asin'], alpha = 0.5)\n",
    "axes[1].hist(discrete_train_df['reviewerID'], alpha = 0.5)\n",
    "axes[1].hist(discrete_test_df['reviewerID'], alpha = 0.5)\n",
    "axes[2].hist(discrete_train_df['overall'], alpha = 0.5)\n",
    "axes[2].hist(discrete_test_df['overall'], alpha = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从图中可以发现，离散后的asin, reviewerID和overall在训练集和测试集基本是同分布的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 28.291456s\n",
      "n_samples: 57039, n_features: 153746\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 5.050851s \n",
      "n_samples: 11208, n_features: 153746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#将reviewText转化成稀疏矩阵\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "X_train_text = vectorizer.fit_transform(train_df['reviewText'])\n",
    "duration = time() - t0\n",
    "print(\"done in %fs\" % duration)\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train_text.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test_text = vectorizer.transform(test_df['reviewText'])\n",
    "duration = time() - t0\n",
    "print(\"done in %fs \" % duration)\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test_text.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 50 best features by a chi-squared test\n",
      "done in 0.487126s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#选取最好的50个特征\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "print(\"Extracting 50 best features by a chi-squared test\" )\n",
    "t0 = time()\n",
    "ch2 = SelectKBest(chi2, k=50)\n",
    "X_train = ch2.fit_transform(X_train_text, y_train)\n",
    "X_test = ch2.transform(X_test_text)\n",
    "\n",
    "new_feature_names = [feature_names[i] for i\n",
    "                         in ch2.get_support(indices=True)]\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abs', 'audio', 'bad', 'band', 'beginner', 'beginners', 'boring', 'calories', 'cardio', 'collection', 'concert', 'dance', 'dvd', 'dvds', 'episodes', 'excellent', 'exercises', 'fitness', 'highly', 'included', 'instruction', 'instructor', 'intermediate', 'movements', 'moves', 'muscles', 'music', 'poses', 'print', 'prints', 'quality', 'section', 'segments', 'series', 'set', 'songs', 'sound', 'stupid', 'tape', 'toning', 'vhs', 'video', 'videos', 'waste', 'weights', 'wonderful', 'workout', 'workouts', 'worst', 'yoga']\n"
     ]
    }
   ],
   "source": [
    "print(new_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<57039x153746 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 5386169 stored elements in Compressed Sparse Row format>,\n",
       " <57039x50 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 112919 stored elements in Compressed Sparse Row format>,\n",
       " <11208x153746 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1047597 stored elements in Compressed Sparse Row format>,\n",
       " <11208x50 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 20983 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#系数矩阵中储存的特征数量\n",
    "X_train_text,X_train, X_test_text, X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对文本特征进行降维 #太慢了还没有做\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.manifold import SpectralEmbedding\n",
    "# t0 = time()\n",
    "# method= SpectralEmbedding(n_components=3)\n",
    "# X_train_embedded = method.fit_transform(X_train)\n",
    "# print(\"done in %fs\" % (time() - t0))\n",
    "# X_train_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = time()\n",
    "# X_test_embedded =  method.transform(X_test)\n",
    "# print(\"done in %fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57039,) (57039, 50)\n"
     ]
    }
   ],
   "source": [
    "print(train_df['reviewerID'].shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8760007715975809, 0.9019965239627862)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max(), X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count begins\n",
      "done in 7.414235s\n",
      "count begins\n",
      "done in 1.377843s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_all</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>First off, allow me to correct a common mistak...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>1987</td>\n",
       "      <td>13</td>\n",
       "      <td>4.776442</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>I am really troubled by this Story and Enterta...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>99</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>2225</td>\n",
       "      <td>21</td>\n",
       "      <td>4.664570</td>\n",
       "      <td>22.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>A near-perfect film version of a downright glo...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>357</td>\n",
       "      <td>4</td>\n",
       "      <td>5.028169</td>\n",
       "      <td>17.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>Keep your expectations low.  Really really low...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>577</td>\n",
       "      <td>14</td>\n",
       "      <td>4.931624</td>\n",
       "      <td>8.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>\"they dont make em like this no more...\"well.....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>461</td>\n",
       "      <td>21</td>\n",
       "      <td>4.704082</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewerID      asin                                         reviewText  \\\n",
       "0    0.052632  0.052632  First off, allow me to correct a common mistak...   \n",
       "1    0.421053  1.000000  I am really troubled by this Story and Enterta...   \n",
       "2    0.000000  0.052632  A near-perfect film version of a downright glo...   \n",
       "3    0.368421  0.842105  Keep your expectations low.  Really really low...   \n",
       "4    0.315789  0.315789  \"they dont make em like this no more...\"well.....   \n",
       "\n",
       "   overall  votes_up  votes_all  label  word_count  char_count  \\\n",
       "0      1.0         6          7      0         416        1987   \n",
       "1      0.6        99        134      0         477        2225   \n",
       "2      0.8        14         14      1          71         357   \n",
       "3      0.2         4          7      0         117         577   \n",
       "4      1.0         3          6      0          98         461   \n",
       "\n",
       "   sentence_count  avg_word_length  avg_sentence_length  \n",
       "0              13         4.776442            32.000000  \n",
       "1              21         4.664570            22.714286  \n",
       "2               4         5.028169            17.750000  \n",
       "3              14         4.931624             8.357143  \n",
       "4              21         4.704082             4.666667  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "# t0 = time()\n",
    "\n",
    "# # 字数计数:计算文本中记号的数量(用空格分隔)\n",
    "# discrete_train_df['word_count'] = discrete_train_df[\"reviewText\"].apply(lambda x: len(str(x).split(\" \"))) \n",
    "\n",
    "# # 字符计数:将每个标记的字符数相加计算\n",
    "# discrete_train_df['char_count'] = discrete_train_df[\"reviewText\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "\n",
    "# # 句子数:计算句子的数量(以句点分隔)\n",
    "# discrete_train_df['sentence_count'] = discrete_train_df[\"reviewText\"].apply(lambda x: len(str(x).split(\".\"))) \n",
    "\n",
    "# # 平均字数:字数除以字数的总和(字符数/字数)\n",
    "# discrete_train_df['avg_word_length'] = discrete_train_df['char_count'] /discrete_train_df['word_count'] \n",
    "\n",
    "# # 平均句子长度:句子长度的总和除以句子的数量(字数/句子数量)\n",
    "# discrete_train_df['avg_sentence_lenght'] = discrete_train_df['word_count'] / discrete_train_df['sentence_count']\n",
    "\n",
    "# print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "# discrete_train_df.head()\n",
    "\n",
    "def counts(df):\n",
    "    print(\"count begins\")\n",
    "    t0 = time()\n",
    "    # 字数计数:计算文本中记号的数量(用空格分隔)\n",
    "    df['word_count'] = df[\"reviewText\"].apply(lambda x: len(str(x).split(\" \"))) \n",
    "    # 字符计数:将每个标记的字符数相加计算\n",
    "    df['char_count'] = df[\"reviewText\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "    # 句子数:计算句子的数量(以句点分隔)\n",
    "    df['sentence_count'] = df[\"reviewText\"].apply(lambda x: len(str(x).split(\".\"))) \n",
    "    # 平均字数:字数除以字数的总和(字符数/字数)\n",
    "    df['avg_word_length'] = df['char_count'] / df['word_count'] \n",
    "    # 平均句子长度:句子长度的总和除以句子的数量(字数/句子数量)\n",
    "    df['avg_sentence_length'] = df['word_count'] / df['sentence_count']\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "def discrete_counts(df, df1,  num = 11): #训练集的测试集标准不一样，应该要改成一样的 \n",
    "    discretedf_train = df.copy()\n",
    "    discretedf_test = df1.copy()\n",
    "    for c in df.columns[1:]: # 遍历每一列特征，跳过前面的列\n",
    "        if c == 'word_count' or c == 'char_count' or c == 'sentence_count' or c == 'avg_word_length' or c == 'avg_sentence_length':\n",
    "            # 离散化特征\n",
    "            discretedf_train[c], bins = pd.qcut(df[c], q = num,labels = False, retbins=True)\n",
    "            discretedf_test[c] = pd.cut(df[c], bins = bins,labels = False)\n",
    "            \n",
    "            #归一化\n",
    "            maxx = discretedf_train[c].max()\n",
    "            discretedf_train[c] = discretedf_train[c]/ maxx\n",
    "            discretedf_test[c] = discretedf_test[c]/ maxx\n",
    "        \n",
    "    return discretedf_train, discretedf_test\n",
    "\n",
    "classes = 11\n",
    "counts(discrete_train_df)\n",
    "counts(discrete_test_df)\n",
    "# discrete_train_df, discrete_test_df = discrete_counts(discrete_train_df, discrete_test_df, classes)\n",
    "discrete_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_all</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "      <td>57039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.257629</td>\n",
       "      <td>0.393775</td>\n",
       "      <td>0.707036</td>\n",
       "      <td>12.387594</td>\n",
       "      <td>18.475850</td>\n",
       "      <td>0.226196</td>\n",
       "      <td>255.126335</td>\n",
       "      <td>1187.168166</td>\n",
       "      <td>15.734778</td>\n",
       "      <td>4.598286</td>\n",
       "      <td>16.931602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.254734</td>\n",
       "      <td>0.295743</td>\n",
       "      <td>0.305948</td>\n",
       "      <td>45.130499</td>\n",
       "      <td>50.149683</td>\n",
       "      <td>0.418371</td>\n",
       "      <td>242.025413</td>\n",
       "      <td>1150.945509</td>\n",
       "      <td>14.385499</td>\n",
       "      <td>0.405145</td>\n",
       "      <td>10.118088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.373626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.344444</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.587021</td>\n",
       "      <td>15.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>1521.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.834740</td>\n",
       "      <td>20.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6084.000000</td>\n",
       "      <td>6510.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4322.000000</td>\n",
       "      <td>20203.000000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>441.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         reviewerID          asin       overall      votes_up     votes_all  \\\n",
       "count  57039.000000  57039.000000  57039.000000  57039.000000  57039.000000   \n",
       "mean       0.257629      0.393775      0.707036     12.387594     18.475850   \n",
       "std        0.254734      0.295743      0.305948     45.130499     50.149683   \n",
       "min        0.000000      0.000000      0.200000      0.000000      5.000000   \n",
       "25%        0.052632      0.157895      0.400000      4.000000      6.000000   \n",
       "50%        0.157895      0.368421      0.800000      6.000000     10.000000   \n",
       "75%        0.421053      0.631579      1.000000     11.000000     18.000000   \n",
       "max        1.000000      1.000000      1.000000   6084.000000   6510.000000   \n",
       "\n",
       "              label    word_count    char_count  sentence_count  \\\n",
       "count  57039.000000  57039.000000  57039.000000    57039.000000   \n",
       "mean       0.226196    255.126335   1187.168166       15.734778   \n",
       "std        0.418371    242.025413   1150.945509       14.385499   \n",
       "min        0.000000      1.000000      6.000000        1.000000   \n",
       "25%        0.000000    100.000000    450.000000        7.000000   \n",
       "50%        0.000000    187.000000    858.000000       12.000000   \n",
       "75%        0.000000    325.000000   1521.000000       20.000000   \n",
       "max        1.000000   4322.000000  20203.000000      386.000000   \n",
       "\n",
       "       avg_word_length  avg_sentence_length  \n",
       "count     57039.000000         57039.000000  \n",
       "mean          4.598286            16.931602  \n",
       "std           0.405145            10.118088  \n",
       "min           1.857143             0.373626  \n",
       "25%           4.344444            12.000000  \n",
       "50%           4.587021            15.826087  \n",
       "75%           4.834740            20.090909  \n",
       "max          10.500000           441.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# discrete_train_df = discrete_train_df.drop(columns = 'avg_sentence_lenghth')\n",
    "# discrete_test_df = discrete_test_df.drop(columns = 'avg_sentence_lenghth')\n",
    "discrete_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, axes = plt.subplots(2, 3, figsize = (16,10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "count = ['word_count', 'char_count', 'sentence_count', 'avg_word_length', 'avg_sentence_length']\n",
    "for i in range(5):\n",
    "    axes[i].hist(discrete_train_df[discrete_train_df['label'] == 0][count[i]], bins = classes, alpha = 0.5)\n",
    "    axes[i].hist(discrete_train_df[discrete_train_df['label'] == 1][count[i]], bins = classes, alpha = 0.5)\n",
    "\n",
    "# plt.hist(discrete_train_df[discrete_train_df['label'] == 0]['word_count'],bins = classes, alpha = 0.5)\n",
    "# plt.hist(discrete_train_df[discrete_train_df['label'] == 1]['word_count'],bins = classes, alpha = 0.5)\n",
    "# print(set(discrete_train_df['word_count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\numpy\\lib\\histograms.py:839: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "d:\\python\\lib\\site-packages\\numpy\\lib\\histograms.py:840: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, axes = plt.subplots(2, 3, figsize = (16,10))\n",
    "axes = axes.flatten()\n",
    "for i in range(5):\n",
    "    axes[i].hist(discrete_train_df[count[i]],bins = classes, alpha = 0.5)\n",
    "    axes[i].hist(discrete_test_df[count[i]], bins = classes,alpha = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<57039x58 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 525514 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将特征合成一个矩阵\n",
    "from scipy.sparse import hstack\n",
    "# train_features = hstack([np.array(discreteID).reshape(-1, 1), np.array(discreteAsin).reshape(-1, 1),\n",
    "#                          X_train, np.array(discreteOverall).reshape(-1, 1)])\n",
    "# test_features = hstack([np.array(test_discreteID).reshape(-1, 1), np.array(test_discreteAsin).reshape(-1, 1),\n",
    "#                          X_train, np.array(test_discreteOverall).reshape(-1, 1)])\n",
    "\n",
    "# #原有信息和文本特征\n",
    "# train_features = hstack([np.array(discrete_train_df['reviewerID']).reshape(-1, 1), np.array(discrete_train_df['asin']).reshape(-1, 1),\n",
    "#                           X_train, np.array(discrete_train_df['overall']).reshape(-1, 1)])\n",
    "# test_features = hstack([np.array(discrete_test_df['reviewerID']).reshape(-1, 1), np.array(discrete_test_df['asin']).reshape(-1, 1),\n",
    "#                          X_test, np.array(discrete_test_df['overall']).reshape(-1, 1)])\n",
    "\n",
    "#加入文本长度等特征\n",
    "\n",
    "count = ['word_count', 'char_count', 'sentence_count', 'avg_word_length', 'avg_sentence_length']\n",
    "train_features = hstack([np.array(discrete_train_df['reviewerID']).reshape(-1, 1), np.array(discrete_train_df['asin']).reshape(-1, 1),\n",
    "                          X_train, np.array(discrete_train_df['overall']).reshape(-1, 1), \n",
    "                         np.array(discrete_train_df['word_count']).reshape(-1, 1),\n",
    "                         np.array(discrete_train_df['char_count']).reshape(-1, 1),\n",
    "                         np.array(discrete_train_df['sentence_count']).reshape(-1, 1),\n",
    "                         np.array(discrete_train_df['avg_word_length']).reshape(-1, 1),\n",
    "                         np.array(discrete_train_df['avg_sentence_length']).reshape(-1, 1)])\n",
    "test_features = hstack([np.array(discrete_test_df['reviewerID']).reshape(-1, 1), np.array(discrete_test_df['asin']).reshape(-1, 1),\n",
    "                         X_test, np.array(discrete_test_df['overall']).reshape(-1, 1),\n",
    "                         np.array(discrete_test_df['word_count']).reshape(-1, 1),\n",
    "                         np.array(discrete_test_df['char_count']).reshape(-1, 1),\n",
    "                         np.array(discrete_test_df['sentence_count']).reshape(-1, 1),\n",
    "                         np.array(discrete_test_df['avg_word_length']).reshape(-1, 1),\n",
    "                         np.array(discrete_test_df['avg_sentence_length']).reshape(-1, 1)])\n",
    "test_features[np.isnan(test_features)] = 0 \n",
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # 划分数据集函数(用来帮助随机采样)\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "class Guess(object):\n",
    "    def __init__(self, RANDOM_SEED = 2020):\n",
    "        self.RAMDOM_SEED = 2020\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if len(X.shape) > 1: #二维数组\n",
    "            rst = np.zeros(X.shape[0])\n",
    "            for i, x in enumerate(X):\n",
    "                 rst[i] = self.predict_(x)\n",
    "        elif len(X) == 0:\n",
    "            rst = -1\n",
    "        else:\n",
    "            rst = self.predict_(X)\n",
    "        return rst\n",
    "    \n",
    "    def predict_(self, x):\n",
    "        return 1\n",
    "\n",
    "\n",
    "#Bagging 方法\n",
    "class Bagging(object):\n",
    "            #replicate_number拔靴采样次数，boot_size每一次采样的训练集的大小, ml选用的分类器\n",
    "    def __init__(self, replicate_number = 10, boot_size = 0.6, ml = 'DecisionTreeClassifier', RANDOM_SEED = 2020): \n",
    "        self.replicate_number = replicate_number\n",
    "        self.boot_size = boot_size\n",
    "        self.ml = ml\n",
    "        self.RANDOM_SEED = RANDOM_SEED\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.models = list(range(self.replicate_number))\n",
    "        for i in range(self.replicate_number):\n",
    "            #每次用不同的random_seed采样\n",
    "            ti = time()\n",
    "            x_train, x_test, y_train, y_test = train_test_split(X,y, test_size= 1 - self.boot_size, random_state=self.RANDOM_SEED + i) \n",
    "            if self.ml == 'LinearSVR':\n",
    "                self.models[i] = LinearSVR()\n",
    "                self.models[i].fit(x_train, y_train)\n",
    "            elif self.ml == 'DecisionTreeClassifier':\n",
    "                self.models[i] = DecisionTreeClassifier(max_depth = 3) #为了避免过拟合，将深度设置为10\n",
    "                self.models[i].fit(x_train, y_train)\n",
    "            elif self.ml == 'DecisionTreeRegressor':\n",
    "                self.models[i] = DecisionTreeRegressor()\n",
    "                self.models[i].fit(x_train, y_train)\n",
    "            elif self.ml == 'KNeighborsClassifier':\n",
    "                self.models[i] = KNeighborsClassifier(n_neighbors=3)\n",
    "                self.models[i].fit(x_train, y_train)\n",
    "            elif self.ml == 'BernoulliNB':\n",
    "                self.models[i] = BernoulliNB()\n",
    "                self.models[i].fit(x_train, y_train)\n",
    "            \n",
    "            elif self.ml == 'LogisticRegression':\n",
    "                self.models[i] = BernoulliNB()\n",
    "                self.models[i].fit(x_train, y_train)\n",
    "            \n",
    "            else:\n",
    "                self.models[i] = Guess()\n",
    "                self.models[i].fit(x_train, y_train)\n",
    "            print(\"round \", i)\n",
    "            print(\"done in %fs\" % (time() - ti))\n",
    "    \n",
    "    def predict(self, X): #平权投票，得出最终的predict\n",
    "        rst = 0\n",
    "        for i in range(self.replicate_number):\n",
    "            pred = self.models[i].predict(X)\n",
    "            rst += pred\n",
    "        rst = rst / self.replicate_number\n",
    "        \n",
    "        return rst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost方法\n",
    "\n",
    "class AdaBoost(object):\n",
    "    #T 重复次数\n",
    "    def __init__(self, T = 5, ml = 'DecisionTreeClassifier'): \n",
    "        self.T = T\n",
    "        self.ml = ml\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.models = list(range(self.T)) #分类器\n",
    "        self.errors = list(range(self.T)) \n",
    "        self.betas = np.ones(self.T) * 2\n",
    "        self.sample_weight = np.ones(X.shape[0]) / X.shape[0]\n",
    "        for i in range(self.T):\n",
    "            print(\"T = \", i)\n",
    "            #根据权重生成模型\n",
    "            ti = time()\n",
    "            if self.ml == 'LinearSVR':\n",
    "                self.models[i] = LinearSVR()\n",
    "                self.models[i].fit(X, y, self.sample_weight)\n",
    "            elif self.ml == 'DecisionTreeClassifier':\n",
    "                self.models[i] = DecisionTreeClassifier(max_depth = 10)\n",
    "                self.models[i].fit(X, y, self.sample_weight)\n",
    "            elif self.ml == 'DecisionTreeRegressor':\n",
    "                self.models[i] = DecisionTreeRegressor()\n",
    "                self.models[i].fit(X, y, self.sample_weight)\n",
    "            elif self.ml == 'KNeighborsClassifier':\n",
    "                self.models[i] = KNeighborsClassifier(n_neighbors=3)\n",
    "                self.models[i].fit(X, y, self.sample_weight)\n",
    "            elif self.ml == 'BernoulliNB':\n",
    "                self.models[i] = BernoulliNB()\n",
    "                self.models[i].fit(X, y, self.sample_weight)\n",
    "            \n",
    "            elif self.ml == 'LogisticRegression':\n",
    "                self.models[i] = BernoulliNB()\n",
    "                self.models[i].fit(X, y, self.sample_weight)\n",
    "            \n",
    "            else:\n",
    "                self.models[i] = Guess()\n",
    "                self.models[i].fit(X, y)\n",
    "            #用这个模型进行预测\n",
    "            pred = self.models[i].predict(X)\n",
    "            #计算所有错误分类样本权重和\n",
    "            self.errors[i] = 0\n",
    "            for j, pre in enumerate(pred):\n",
    "                if pre != y[j]: \n",
    "                    self.errors[i] = self.errors[i] + self.sample_weight[j]\n",
    "            \n",
    "            print(\"error:\", self.errors[i])\n",
    "            #计算beta\n",
    "            self.betas[i] = self.errors[i] / (1 - self.errors[i])\n",
    "            \n",
    "            if self.errors[i] > 0.5:\n",
    "                print('a better C is required')\n",
    "                self.T = i + 1\n",
    "                return\n",
    "            if self.errors[i] == 0: #如果全做对了，beta等于0.99，返回\n",
    "                self.betas[i] = 0.99\n",
    "                print('error = 0')\n",
    "                self.T = i + 1\n",
    "                return ;\n",
    "\n",
    "            #跟新每个样本的权重，并归一化\n",
    "            for j, pre in enumerate(pred):\n",
    "                if pre == y[j]: \n",
    "                    self.sample_weight[j] = self.sample_weight[j] * self.betas[i]\n",
    "            sumw = sum(self.sample_weight)\n",
    "            print(\"sum of sample_weight:\", sumw)\n",
    "            for j, w in enumerate(self.sample_weight):\n",
    "                self.sample_weight[j] = w / sumw\n",
    "            print(\"done in %fs\" % (time() - ti))\n",
    "       \n",
    "    def predict(self, X): #融合所有假设，各自投票权重为1/beta\n",
    "        self.pollweight = np.log(1 / self.betas)\n",
    "        rst = 0\n",
    "        for i in range(self.T):\n",
    "            pred = self.models[i].predict(X)\n",
    "            rst += pred * self.pollweight[i]\n",
    "        rst = rst / sum(self.pollweight)\n",
    "        return rst\n",
    "                   \n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  0\n",
      "done in 0.903646s\n",
      "round  1\n",
      "done in 0.922688s\n",
      "round  2\n",
      "done in 0.945331s\n",
      "round  3\n",
      "done in 0.892061s\n",
      "round  4\n",
      "done in 0.938853s\n",
      "round  5\n",
      "done in 0.968286s\n",
      "round  6\n",
      "done in 0.927207s\n",
      "round  7\n",
      "done in 0.964439s\n",
      "round  8\n",
      "done in 0.935210s\n",
      "round  9\n",
      "done in 0.940035s\n",
      "done in 9.343560s\n",
      "done in 0.306069s\n",
      "[0.  0.  0.  ... 0.  0.4 0.1]\n",
      "AUC score: 0.6977679649510288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "#bagging + 决策树\n",
    "t0 = time()\n",
    "model = Bagging(ml = 'DecisionTreeClassifier')\n",
    "model.fit(train_features, y_train)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "pred = model.predict(train_features)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(pred)\n",
    "print(\"AUC score:\", roc_auc_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  0\n",
      "done in 2.287439s\n",
      "round  1\n",
      "done in 2.682568s\n",
      "round  2\n",
      "done in 1.770796s\n",
      "round  3\n",
      "done in 1.973726s\n",
      "round  4\n",
      "done in 2.100352s\n",
      "round  5\n",
      "done in 2.646968s\n",
      "round  6\n",
      "done in 2.309515s\n",
      "round  7\n",
      "done in 2.340528s\n",
      "round  8\n",
      "done in 2.256045s\n",
      "round  9\n",
      "done in 2.234341s\n",
      "done in 22.604295s\n",
      "done in 0.027606s\n",
      "[1.55948243e-04 8.93840483e-05 8.14122478e-05 ... 8.33285168e-05\n",
      " 7.66016125e-01 1.08685742e-04]\n",
      "AUC score: 0.6197767466229069\n"
     ]
    }
   ],
   "source": [
    "# Bagging + LinearSVR(SVM)\n",
    "t0 = time()\n",
    "model2 = Bagging(ml = 'LinearSVR')\n",
    "model2.fit(train_features, y_train)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "pred2 = model2.predict(train_features)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(pred2)\n",
    "print(\"AUC score:\", roc_auc_score(y_train, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of sample_weight: 0.40119917950827827\n",
      "T =  0\n",
      "done in 5.194106s\n",
      "sum of sample_weight: 0.5565274622319083\n",
      "T =  1\n",
      "done in 5.733508s\n",
      "sum of sample_weight: 0.7399509272162568\n",
      "T =  2\n",
      "done in 5.181646s\n",
      "sum of sample_weight: 0.7335251172038909\n",
      "T =  3\n",
      "done in 5.644782s\n",
      "sum of sample_weight: 0.7684292691086073\n",
      "T =  4\n",
      "done in 5.423764s\n",
      "done in 27.182788s\n",
      "done in 0.166034s\n",
      "[0.50365791 0.14054557 0.24527575 ... 0.14054557 0.39892773 0.64420348]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8283635687092246"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adaboost + 决策树\n",
    "t0 = time()\n",
    "model3 = AdaBoost(ml = 'DecisionTreeClassifier')\n",
    "model3.fit(train_features, y_train)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "t0 = time()\n",
    "pred3 = model3.predict(train_features)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(pred3)\n",
    "roc_auc_score(y_train, pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a better C is required\n",
      "done in 1.908395s\n",
      "done in 0.002981s\n",
      "[ 1.12199537e-07 -3.92700727e-07  5.93557996e-07 ... -1.69689759e-07\n",
      "  1.88953182e-04  3.87520584e-06]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6180569443332905"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adaboost + linearSVR(SVM)\n",
    "t0 = time()\n",
    "model4 = AdaBoost(ml = 'LinearSVR')\n",
    "model4.fit(train_features, y_train)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "t0 = time()\n",
    "pred4 = model4.predict(train_features)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(pred4)\n",
    "roc_auc_score(y_train, pred4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 结果分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC值：\n",
    "- Bagging + SVM ： 0.6197 （不稳定，每次都会变）\n",
    "- Bagging + 决策树：0.6977\n",
    "- AdaBoost.M1 + SVM：0.6181\n",
    "- AdaBoost.M1 + 决策树：0.8284\n",
    "\n",
    "分析：\n",
    "\n",
    "在调整决策树深度以前，AUC一度达到0.9999左右，很明显是过拟合了，因此将最大深度设置为10。\n",
    "\n",
    "- SVM学习器在这里很弱（应该是因为特征工程没有做好），错误率大于0.5，使得AdaBoost.M1第一轮就停了。\n",
    "\n",
    "- SVM学习器和Bagging配合，每次AUC值都会变，甚至低于0.5，效果不理想。\n",
    "\n",
    "- 像ID这种特征，虽然是连续的，但是其值的大小其实对label的贡献很小。\n",
    "\n",
    "- 特征工程是存在问题的，稀疏矩阵没有离散化。因此决策树模型很可能过拟合了。\n",
    "\n",
    "- 特别是AdaBoost.M1 + 决策树的模型，太复杂的基学习器+Adaboost, 过拟合更严重，因此在训练集上的AUC值比较大。\n",
    "\n",
    "- 而Bagging是在训练集上随机采样，过拟合只因为决策树本身，所以也会过拟合，但没那么严重。\n",
    "\n",
    "需要的改进：\n",
    "特征工程需要重新做"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、其他基分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bagging + KNN(n = 3)\n",
    "t0 = time()\n",
    "model5 = Bagging(ml = 'KNeighborsClassifier')\n",
    "model5.fit(train_features, y_train)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "pred5 = model5.predict(train_features)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(pred5)\n",
    "print(\"AUC score:\", roc_auc_score(y_train, pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57039"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoost + KNN(n = 3)\n",
    "t0 = time()\n",
    "model6 = AdaBoost(ml = 'KNeighborsClassifier')\n",
    "model6.fit(train_features, y_train)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "pred6 = model6.predict(train_features)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(pred6)\n",
    "print(\"AUC score:\", roc_auc_score(y_train, pred6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging + BernoulliNB\n",
    "t0 = time()\n",
    "model7 = Bagging(ml = 'BernoulliNB')\n",
    "model7.fit(train_features, y_train)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "pred7 = model7.predict(train_features)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(pred7)\n",
    "print(\"AUC score:\", roc_auc_score(y_train, pred7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost + BernoulliNB\n",
    "t0 = time()\n",
    "model8 = AdaBoost(ml = 'BernoulliNB', T = 20)\n",
    "model8.fit(train_features, y_train)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "t0 = time()\n",
    "pred8 = model8.predict(train_features)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(pred8)\n",
    "print(\"AUC score:\", roc_auc_score(y_train, pred8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    pred9 = model8.models[i].predict(train_features)\n",
    "    print(\"AUC score:\", roc_auc_score(y_train, pred9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现一个有趣的现象，奇数轮的AUC值在0.5左右，而偶数轮的auc值先上升后下降。\n",
    "\n",
    "最终的AUC值大于所有单轮的AUC值。说明AdaBoost结合贝叶斯分类是有效的，但也同时存在过拟合的可能性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、采用不同特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 仅文本特征\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaboost + 决策树 + 仅文本\n",
    "t0 = time()\n",
    "model9 = AdaBoost(ml = 'DecisionTreeClassifier')\n",
    "model9.fit(X_train, y_train)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "pred9 = model9.predict(X_train)\n",
    "print(pred9)\n",
    "print(\"AUC:\", roc_auc_score(y_train, pred9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2仅文本以外的离散特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_f_train = np.hstack([np.array(discrete_train_df['reviewerID']).reshape(-1, 1), np.array(discrete_train_df['asin']).reshape(-1, 1),\n",
    "                         np.array(discrete_train_df['overall']).reshape(-1, 1), \n",
    "                         np.array(discrete_train_df['word_count']).reshape(-1, 1),\n",
    "                         np.array(discrete_train_df['char_count']).reshape(-1, 1),\n",
    "                         np.array(discrete_train_df['sentence_count']).reshape(-1, 1),\n",
    "                         np.array(discrete_train_df['avg_word_length']).reshape(-1, 1),\n",
    "                         np.array(discrete_train_df['avg_sentence_length']).reshape(-1, 1)])\n",
    "discrete_f_test = np.hstack([np.array(discrete_test_df['reviewerID']).reshape(-1, 1), np.array(discrete_test_df['asin']).reshape(-1, 1),\n",
    "                         np.array(discrete_test_df['overall']).reshape(-1, 1),\n",
    "                         np.array(discrete_test_df['word_count']).reshape(-1, 1),\n",
    "                         np.array(discrete_test_df['char_count']).reshape(-1, 1),\n",
    "                         np.array(discrete_test_df['sentence_count']).reshape(-1, 1),\n",
    "                         np.array(discrete_test_df['avg_word_length']).reshape(-1, 1),\n",
    "                         np.array(discrete_test_df['avg_sentence_length']).reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaboost + 决策树 + 仅文本以外离散特征\n",
    "t0 = time()\n",
    "model10 = AdaBoost(ml = 'DecisionTreeClassifier')\n",
    "model10.fit(discrete_f_train, y_train)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "pred10 = model10.predict(discrete_f_train)\n",
    "print(pred10)\n",
    "print(\"AUC:\", roc_auc_score(y_train, pred10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现：使用仅文本以外的离散特征效果比仅采用文本特征效果更好，这很可能是文本特征没有进行离散化，因此过拟合了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model10.predict(discrete_f_test)\n",
    "\n",
    "test_pred = [np.argmax(x) for x in test_pred]\n",
    " \n",
    "#将测试集预测结果写入文件\n",
    "output=pd.DataFrame({'Id':test_df.id,'Predicted':test_pred})\n",
    "output.to_csv('data/results.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.special import comb\n",
    "from scipy.integrate import quad\n",
    "\n",
    "#概率密度公式\n",
    "f = lambda q, n, p: comb(n, n*q)*math.pow(p, n * q)*math.pow((1-p), n * ( 1 - q))\n",
    "\n",
    "\n",
    "#求0.9 ~ 1.0的密度定积分，划分成宽度为0.1的区间求和，作为估计实际vote_up大于等于0.9的概率（即高质量评论）\n",
    "ran = np.array(range(90,100))/100\n",
    "rest = np.array(range(0,90))/100\n",
    "def prob(qq, nn):\n",
    "    p = 0\n",
    "    q = qq / nn\n",
    "    for i in ran:\n",
    "        p = p + 1/10 * f(q, nn, i)\n",
    "    ap = p\n",
    "    for i in rest:\n",
    "        ap = ap + 1/10 * f(q, nn, i)\n",
    "    return p/ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8163902340048661"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob(15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████▉                            | 35684/57039 [03:02<01:50, 192.51it/s]d:\\python\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      " 84%|██████████████████████████████████████████████████████████████▋            | 47700/57039 [04:02<00:44, 210.08it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "probs = []\n",
    "for i in tqdm(range(len(train_df['votes_up']))):\n",
    "    probs.append(prob(train_df['votes_up'][i], train_df['votes_all'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.array(probs)\n",
    "train_df['probs'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76059945675"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_df['probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_all</th>\n",
       "      <th>label</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7885</td>\n",
       "      <td>3901</td>\n",
       "      <td>First off, allow me to correct a common mistak...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.517396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52087</td>\n",
       "      <td>47978</td>\n",
       "      <td>I am really troubled by this Story and Enterta...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>6.577389e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5701</td>\n",
       "      <td>3667</td>\n",
       "      <td>A near-perfect film version of a downright glo...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4.917142e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47191</td>\n",
       "      <td>40892</td>\n",
       "      <td>Keep your expectations low.  Really really low...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7.477548e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40957</td>\n",
       "      <td>15367</td>\n",
       "      <td>\"they dont make em like this no more...\"well.....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.658558e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57034</th>\n",
       "      <td>58315</td>\n",
       "      <td>29374</td>\n",
       "      <td>If you like beautifully shot, well acted films...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1.409772e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57035</th>\n",
       "      <td>23328</td>\n",
       "      <td>45548</td>\n",
       "      <td>This is a great set of films Wayne did Fox and...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>6.911284e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57036</th>\n",
       "      <td>27203</td>\n",
       "      <td>42453</td>\n",
       "      <td>It's what's known as a comedy of manners. It's...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.065794e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57037</th>\n",
       "      <td>33992</td>\n",
       "      <td>44891</td>\n",
       "      <td>Ellen can do no wrong as far a creating wonder...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.065794e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57038</th>\n",
       "      <td>27478</td>\n",
       "      <td>19198</td>\n",
       "      <td>I agree with everyone else that this is a grea...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7.605995e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57039 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID   asin                                         reviewText  \\\n",
       "0            7885   3901  First off, allow me to correct a common mistak...   \n",
       "1           52087  47978  I am really troubled by this Story and Enterta...   \n",
       "2            5701   3667  A near-perfect film version of a downright glo...   \n",
       "3           47191  40892  Keep your expectations low.  Really really low...   \n",
       "4           40957  15367  \"they dont make em like this no more...\"well.....   \n",
       "...           ...    ...                                                ...   \n",
       "57034       58315  29374  If you like beautifully shot, well acted films...   \n",
       "57035       23328  45548  This is a great set of films Wayne did Fox and...   \n",
       "57036       27203  42453  It's what's known as a comedy of manners. It's...   \n",
       "57037       33992  44891  Ellen can do no wrong as far a creating wonder...   \n",
       "57038       27478  19198  I agree with everyone else that this is a grea...   \n",
       "\n",
       "       overall  votes_up  votes_all  label         probs  \n",
       "0          5.0         6          7      0  2.517396e-01  \n",
       "1          3.0        99        134      0  6.577389e-09  \n",
       "2          4.0        14         14      1  4.917142e-01  \n",
       "3          1.0         4          7      0  7.477548e-03  \n",
       "4          5.0         3          6      0  4.658558e-03  \n",
       "...        ...       ...        ...    ...           ...  \n",
       "57034      2.0        12         21      0  1.409772e-05  \n",
       "57035      5.0        15         18      0  6.911284e-02  \n",
       "57036      3.0         4          5      0  2.065794e-01  \n",
       "57037      5.0         4          5      0  2.065794e-01  \n",
       "57038      2.0         5          5      1  7.605995e-01  \n",
       "\n",
       "[57039 rows x 8 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9449053683077058"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "st.norm.cdf(0, loc=2, scale=1) # 均值为 2，标准差为 1 的正态分布在 0 处的累计分布概率值\n",
    "\n",
    "st.norm.cdf([-1, 0, 1])\n",
    "\n",
    "st.binom.cdf(90, n = 100, p = 0.85)\n",
    "# st.binom.pmf(4, n=100, p=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-0.054996133220328265, pvalue=0.9574902045208937)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "a = [99.3, 98.7, 100.5, 101.2, 98.3, 99.7, 99.5, 102.1, 100.5]\n",
    "st.ttest_1samp(a, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [1]*8+ [0]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-0.7499999999999999, pvalue=0.4724044424553536)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.ttest_1samp(b, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [1]*1999+ [0]*20\n",
    "z, p = st.ttest_1samp(c, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5210544250097746e-266"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e210986d3c8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#将reviewText列转化为向量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mVectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mreviewX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviewText'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1839\u001b[0m         \"\"\"\n\u001b[0;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1841\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1842\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m-> 1199\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m             \u001b[0mindices_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m         \u001b[0mj_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1143\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "#将reviewText列转化为向量\n",
    "Vectorizer = TfidfVectorizer(max_features = 50, ngram_range = (1, 3))\n",
    "reviewX = Vectorizer.fit_transform(train_df['reviewText'])\n",
    "print(Vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones((100, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ones(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bagging(ml = 'LinearSVR')\n",
    "model.fit(x, y)\n",
    "pred = model.predict(np.array([[1, 1, 1, 1], [2, 1, 1, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1.2])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "error = 0\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoost(ml = 'DecisionTreeRegressor')\n",
    "model.fit(x, y)\n",
    "pred = model.predict(np.array([[1, 1, 1, 1], [2, 1, 1, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01005034, 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pollweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
      "662904832/662903077 [==============================] - 106s 0us/step\n",
      "C:\\Users\\Yujing\\.keras\\datasets\\multi_cased_L-12_H-768_A-12\\bert_config.json C:\\Users\\Yujing\\.keras\\datasets\\multi_cased_L-12_H-768_A-12\\bert_model.ckpt C:\\Users\\Yujing\\.keras\\datasets\\multi_cased_L-12_H-768_A-12\\vocab.txt\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抄作业bert\n",
    "\n",
    "import pandas as pd\n",
    "import codecs, gc\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    " \n",
    "maxlen = 100  #设置序列长度为120，要保证序列长度不超过512\n",
    " \n",
    "#预训练好的模型\n",
    "\n",
    "config_path = 'uncased_L-12_H-768_A-12/bert_config.json'\n",
    "checkpoint_path = 'uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "dict_path = 'uncased_L-12_H-768_A-12/vocab.txt'\n",
    " \n",
    "#将词表中的词编号转换为字典\n",
    "token_dict = {}\n",
    "with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)\n",
    " \n",
    "# 重写tokenizer        \n",
    "class OurTokenizer(Tokenizer):\n",
    "    def _tokenize(self, text):\n",
    "        R = []\n",
    "        for c in text:\n",
    "            if c in self._token_dict:\n",
    "                R.append(c)\n",
    "            elif self._is_space(c):\n",
    "                R.append('[unused1]')  # 用[unused1]来表示空格类字符\n",
    "            else:\n",
    "                R.append('[UNK]')  # 不在列表的字符用[UNK]表示\n",
    "        return R\n",
    "    \n",
    "tokenizer = OurTokenizer(token_dict)\n",
    " \n",
    "#让每条文本的长度相同，用0填充\n",
    "def seq_padding(X, padding=0):\n",
    "    L = [len(x) for x in X]\n",
    "    ML = max(L)\n",
    "    return np.array([\n",
    "        np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x for x in X\n",
    "    ])\n",
    " \n",
    "#data_generator只是一种为了节约内存的数据方式\n",
    "class data_generator:\n",
    "    def __init__(self, data, batch_size=32, shuffle=True):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.steps = len(self.data) // self.batch_size\n",
    "        if len(self.data) % self.batch_size != 0:\n",
    "            self.steps += 1\n",
    " \n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    " \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            idxs = list(range(len(self.data)))\n",
    " \n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(idxs)\n",
    " \n",
    "            X1, X2, Y = [], [], []\n",
    "            for i in idxs:\n",
    "                d = self.data[i]\n",
    "                text = d[0][:maxlen]\n",
    "                x1, x2 = tokenizer.encode(first=text)\n",
    "                y = d[1]\n",
    "                X1.append(x1)\n",
    "                X2.append(x2)\n",
    "                Y.append([y])\n",
    "                if len(X1) == self.batch_size or i == idxs[-1]:\n",
    "                    X1 = seq_padding(X1)\n",
    "                    X2 = seq_padding(X2)\n",
    "                    Y = seq_padding(Y)\n",
    "                    yield [X1, X2], Y[:, 0, :]\n",
    "                    [X1, X2, Y] = [], [], []\n",
    " \n",
    "# 计算top-k正确率,当预测值的前k个值中存在目标类别即认为预测正确                 \n",
    "def acc_top1(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=1)\n",
    " \n",
    "#bert模型设置\n",
    "def build_bert(nclass):\n",
    "    bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, seq_len=None)  #加载预训练模型\n",
    " \n",
    "    for l in bert_model.layers:\n",
    "        l.trainable = True\n",
    " \n",
    "    x1_in = Input(shape=(None,))\n",
    "    x2_in = Input(shape=(None,))\n",
    " \n",
    "    x = bert_model([x1_in, x2_in])\n",
    "    x = Lambda(lambda x: x[:, 0])(x) # 取出[CLS]对应的向量用来做分类\n",
    "    p = Dense(nclass, activation='softmax')(x)\n",
    " \n",
    "    model = Model([x1_in, x2_in], p)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(1e-5),    #用足够小的学习率\n",
    "                  metrics=['accuracy', acc_top2])\n",
    "    print(model.summary())\n",
    "    return model\n",
    " \n",
    "#训练数据、测试数据和标签转化为模型输入格式\n",
    "DATA_LIST = []\n",
    "for data_row in train_df.iloc[:].itertuples():\n",
    "    DATA_LIST.append((data_row.reviewText, to_categorical(data_row.label, 2)))\n",
    "DATA_LIST = np.array(DATA_LIST)\n",
    " \n",
    "DATA_LIST_TEST = []\n",
    "for data_row in test_df.iloc[:].itertuples():\n",
    "    DATA_LIST_TEST.append((data_row.reviewText, to_categorical(0, 2)))\n",
    "DATA_LIST_TEST = np.array(DATA_LIST_TEST)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"First off, allow me to correct a common mistake that was made by more than one reviewer here: This is most certainly not the first film ever made where animated characters interact with live actors. Pete's Dragon (1977), Mary Poppins (1964) and Song of the South (1946) all predate it, and if you want a lesson in cartoon history, so does Gertie the Dinosaur (1914). But that doesn't mean Who Framed Roger Rabbit is not a landmark film. It was revolutionary for its degree of interaction between the toons and the human characters, done so perfectly that they seem completely natural at first glance, but then amaze when you take a closer look - little things like Jessica Rabbit pinching Eddie Valiant's cheek, or Roger Rabbit hiding under the water in Valiant's sink, or beneath his coat, little details that took very creative special effects to be made convincing. It's also unique and original in the fact that some of it takes place in the real world, featuring animated characters, and some in an animated world, featuring live actors; and in that manner, it predates Cool World, Space Jam and anything following.Who Framed Roger Rabbit is wonderfully funny, directed more at an adult audience than children. Bob Hoskins and Christopher Lloyd make a terrific impression in the lead roles, and manage to stay remarkably serious and convincing while conversing and interacting with entirely imaginary characters. Charles Fleischer is beyond brilliant in the voice of Roger Rabbit (as well as that of Benny the Cab) and Kathleen Turner as Jessica Rabbit is also terrific, a femme fatale so classic that it's ridiculous. The entire film excels with intelligent humor that would appeal to both children and adults, and it's a treat for animation buffs, with references to historical toons from the Foxy cartoons of the 20s, through Betty Boop, Dumbo and Bambi to Bugs Bunny and Mickey Mouse.Who Framed Roger Rabbit is one of the defining films of my childhood; I think that's true for almost anyone born in the 80s. I still have a warm place in my heart for Roger and Eddie Valiant, and a cold one for Judge Doom, who gave me nightmares for weeks after I saw it upon its initial release when I was four (he still gives me chills, by the way, when he first starts talking in his squeaky voice). If you somehow manages to avoid it, do watch it, and if you're willing, it's well worth the purchase, too.\",\n",
       "        array([1., 0.], dtype=float32)],\n",
       "       [\"I am really troubled by this Story and Entertained by the way it was presented.  The troubling part is that this is said to be a true story.***Stop reading if you don't like spoilers.***The story starts with Daniel Lugo (Mark Wahlberg) running from what is an obvious raid on his place of employment, he's hit by a car and then the story flashes back to 6 Months earlier.Daniel is a personal trainer at a local Miami Gym and he comes in contact with a very well to do Colombian-Jewish Entrepreneur.  The Entrepreneur's name is withheld to protect the innocent but, needless to say, this guy hires Daniel as Personal Trainer and begins to tell him all about his success in life.Now Daniel attends a Johnny Wu (Never actually happened) seminar where he is convinced he is A doer and only needs to come up with a plan then make it happen.One thing leads to another Daniel recruits his two friends, Paul and Adrian, to come up with a plan of how they're going to take the Entrepreneurs life, money, and property away to make it their own.Needless to say, this whole thing leads to kidnapping, extortion, fraud, attempted murder, a double murder, and two death penalties for 6 months of living the high life.The acting was decent overall but, playing three dumb, homicidal, muscle heads (no this is not an insult to weight lifters, these guys really were dumb) probably isn't all that challenging.The movie itself was actually very entertaining, disturbing, and actually well done.  I was given tickets to a screening but, I would have honestly paid to see this movie had I not known what I know now.If you're okay with somewhat morbidly bizarre comedies then you won't be disappointed by this.  My biggest struggle with the movie was the glamorization of some very violent and tasteless acts.  This is evidenced by the fact Lugo wasn't stupid, some characters were fictional and some were only half fictional and the wife of doorbal actually aided in the cleanup of the two homicides.  In other words, Michael Bay and company went out of the way to make this story more funny than it really was.Seriously, there are somethings that cannot be unseen or unlearned and this movie has both of these elements.  I would have blissfully enjoyed my suspended reality had they not have flashed across the screen a reminder that it was still a true story amidst two people trying to return a chainsaw with blood and hair on it and the other guy grilling hand that were chopped off their victims.  At that point, the movie went from more funny than disturbing to more disturbing than funny.I dunno, call me old fashioned but, I cannot in good conscience laugh at somebody else's misfortune unless, I suspend reality.\",\n",
       "        array([1., 0.], dtype=float32)],\n",
       "       ['A near-perfect film version of a downright gloomy play, &quot;The Glass Menagerie&quot; successfully captures the atmosphere of futility and hopelessness that permeated the play and made it such a success. The choice  of actors is quite good, and I am thankful that the complete plot was  preserved, rather than attempting to alter it in favor of a more active  storyline. Eccentric, yes, depressing, yes, effective - quite so.',\n",
       "        array([0., 1.], dtype=float32)],\n",
       "       ...,\n",
       "       [\"It's what's known as a comedy of manners. It's a form of entertainment which makes fun of the affectations, habits, values and manners of our times through characters familiar to us in our encounters with them like an old person pretending to be young, the career executive, or the playboy. The plot usually revolves around a scandal but in this case, The Big Year deals with a project that gets out of hand. The characters lose sight of the priorities in their lives, struggle to recover them or discover new ones. The plot is less important than the witty dialogue between them. At their best they can satirize the hypocrisy and pretension in society. Unlike the unbeaten Miami Dolphins who can do nothing but wait until every team has suffered a loss before they can toast that their record is safe for another year, Kenny Bostick can actually do something about it. He spent an entire year of his life setting a record number of sightings. Now sane folk know that records are meant to be broken but it means so much to Bostick's self esteem that he can't allow it to be broken by anybody but himself. It's really an exercise in vanity by all three characters except the other two still bear a sense of responsibility to the people around them. In the end one discovers his next wife while the other re-discovers his family when they learn that there are more important things in their life than a big year and birds. The acting is fine. Beautiful photography. The writing is weak and the script loses focus. One guy will throw his life away. It's the job of the other two characters to learn why he's so reckless. Learn why they would never do it themselves but can hardly lecture him themselves when their own behavior leaves much to be desired. It had potential. I liked it. But it lacks punch and misses too many points about our times. Where's the dialogue? There's an extended version with another 40 minutes. Was it cut away for a shorter fast-paced film? Simply not worth the time?? Don't know. It's a shame that this film was lost but cinema like the theatre demands good writing.\",\n",
       "        array([1., 0.], dtype=float32)],\n",
       "       [\"Ellen can do no wrong as far a creating wonderful workouts for women! It is graceful, energizing, toning and rejuvinating all at the same time. I used light weighted gloves for this and it bumped it way up for a cardio effect and arm toning! It is a must-have workout if you are an Ellen Barrett fan or if you are new to her- get it, you won't be sorry!\",\n",
       "        array([1., 0.], dtype=float32)],\n",
       "       ['I agree with everyone else that this is a great film, but this DVD is unwatchable on a video projector. This is a second-or-third generation 3/4\" video tape copy and is totally smeared and fuzzy. And this piece of doo-doo cost me $19.I thought this was an official release, but somehow this Paramount film has apparently fallen into public domain. I only hope that some other video company can track down the negative and do a proper transfer. Until then, you can watch this on your laptop in a tiny window. It shouldn\\'t look as bad as it does on my 6\\' screen.If you\\'ve got a mojo for a Bob Hope horror comedy, his next film was \"The Ghostbreakers\" and is available from MCA in great condition.',\n",
       "        array([0., 1.], dtype=float32)]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_3 (Functional)       (None, None, 768)    108891648   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 768)          0           functional_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            1538        lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 108,893,186\n",
      "Trainable params: 108,893,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_bert(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_pred = np.zeros((len(data), 2))\n",
    "# test_model_pred = np.zeros((len(data_test), 2))\n",
    "\n",
    "# X_train, X_valid, = data[train_fold, :], data[test_fold, :]\n",
    "\n",
    "# train_D = data_generator(, shuffle=True)\n",
    "# valid_D = data_generator(X_valid, shuffle=True)\n",
    "# test_D = data_generator(data_test, shuffle=False)\n",
    "\n",
    "# model.fit_generator(\n",
    "#             train_D.__iter__(),\n",
    "#             steps_per_epoch=len(train_D),\n",
    "#             epochs=5,\n",
    "#             validation_data=valid_D.__iter__(),\n",
    "#             validation_steps=len(valid_D),\n",
    "#             callbacks=[early_stopping, plateau, checkpoint],\n",
    "# )\n",
    "\n",
    "\n",
    "# train_model_pred[test_fold, :] = model.predict_generator(valid_D.__iter__(), steps=len(valid_D), verbose=1)\n",
    "# test_model_pred += model.predict_generator(test_D.__iter__(), steps=len(test_D), verbose=1)\n",
    "\n",
    "\n",
    "# train_model_pred, test_model_pred = run_cv(2, DATA_LIST, None, DATA_LIST_TEST)\n",
    " \n",
    "# test_pred = [np.argmax(x) for x in test_model_pred]\n",
    " \n",
    "# #将测试集预测结果写入文件\n",
    "# output=pd.DataFrame({'Id':test_df.id,'Predicted':test_pred})\n",
    "# output.to_csv('data/results.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_9 (Functional)       (None, None, 768)    108891648   input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 768)          0           functional_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            1538        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 108,893,186\n",
      "Trainable params: 108,893,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From <ipython-input-13-6869c032b1fa>:25: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/5\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.5392 - accuracy: 0.7708 - acc_top2: 0.7708WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,acc_top2,val_loss,val_accuracy,val_acc_top2\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,acc_top2,val_loss,val_accuracy,val_acc_top2,lr\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "892/892 [==============================] - 9464s 11s/step - loss: 0.5392 - accuracy: 0.7708 - acc_top2: 0.7708 - val_loss: 0.5268 - val_accuracy: 0.7759 - val_acc_top2: 0.7759\n",
      "Epoch 2/5\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.7714 - acc_top2: 0.7714WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,acc_top2,val_loss,val_accuracy,val_acc_top2\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,acc_top2,val_loss,val_accuracy,val_acc_top2,lr\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "892/892 [==============================] - 9817s 11s/step - loss: 0.5275 - accuracy: 0.7714 - acc_top2: 0.7714 - val_loss: 0.5241 - val_accuracy: 0.7760 - val_acc_top2: 0.7760\n",
      "Epoch 3/5\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.7719 - acc_top2: 0.7719WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,acc_top2,val_loss,val_accuracy,val_acc_top2\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,acc_top2,val_loss,val_accuracy,val_acc_top2,lr\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "892/892 [==============================] - 10825s 12s/step - loss: 0.5196 - accuracy: 0.7719 - acc_top2: 0.7719 - val_loss: 0.5182 - val_accuracy: 0.7737 - val_acc_top2: 0.7737\n",
      "Epoch 4/5\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.7727 - acc_top2: 0.7727 WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,acc_top2,val_loss,val_accuracy,val_acc_top2\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,acc_top2,val_loss,val_accuracy,val_acc_top2,lr\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "892/892 [==============================] - 13774s 15s/step - loss: 0.5084 - accuracy: 0.7727 - acc_top2: 0.7727 - val_loss: 0.5174 - val_accuracy: 0.7757 - val_acc_top2: 0.7757\n",
      "Epoch 5/5\n",
      "581/892 [==================>...........] - ETA: 42:48 - loss: 0.4953 - accuracy: 0.7751 - acc_top2: 0.7751"
     ]
    }
   ],
   "source": [
    "#交叉验证训练和测试模型\n",
    "def run_cv(nfold, data, data_labels, data_test):\n",
    "    kf = KFold(n_splits=nfold, shuffle=True, random_state=520).split(data)\n",
    "    train_model_pred = np.zeros((len(data), 2))\n",
    "    test_model_pred = np.zeros((len(data_test), 2))\n",
    " \n",
    "    for i, (train_fold, test_fold) in enumerate(kf):\n",
    "        X_train, X_valid, = data[train_fold, :], data[test_fold, :]\n",
    " \n",
    "        model = build_bert(2)\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=3)   #早停法，防止过拟合\n",
    "        plateau = ReduceLROnPlateau(monitor=\"val_acc\", verbose=1, mode='max', factor=0.5, patience=2) #当评价指标不在提升时，减少学习率\n",
    "        checkpoint = ModelCheckpoint('./bert_dump/' + str(i) + '.hdf5', monitor='val_acc',verbose=2, save_best_only=True, mode='max', save_weights_only=True) #保存最好的模型\n",
    " \n",
    "        train_D = data_generator(X_train, shuffle=True)\n",
    "        valid_D = data_generator(X_valid, shuffle=True)\n",
    "        test_D = data_generator(data_test, shuffle=False)\n",
    "        #模型训练\n",
    "        model.fit_generator(\n",
    "            train_D.__iter__(),\n",
    "            steps_per_epoch=len(train_D),\n",
    "            epochs=5,\n",
    "            validation_data=valid_D.__iter__(),\n",
    "            validation_steps=len(valid_D),\n",
    "            callbacks=[early_stopping, plateau, checkpoint],\n",
    "        )\n",
    " \n",
    "        # model.load_weights('./bert_dump/' + str(i) + '.hdf5')\n",
    " \n",
    "        # return model\n",
    "        train_model_pred[test_fold, :] = model.predict_generator(valid_D.__iter__(), steps=len(valid_D), verbose=1)\n",
    "        test_model_pred += model.predict_generator(test_D.__iter__(), steps=len(test_D), verbose=1)\n",
    " \n",
    "        del model\n",
    "        gc.collect()   #清理内存\n",
    "        K.clear_session()   #clear_session就是清除一个session\n",
    "        # break\n",
    " \n",
    "    return train_model_pred, test_model_pred\n",
    " \n",
    "#n折交叉验证\n",
    "train_model_pred, test_model_pred = run_cv(2, DATA_LIST, None, DATA_LIST_TEST)\n",
    " \n",
    "test_pred = [np.argmax(x) for x in test_model_pred]\n",
    " \n",
    "#将测试集预测结果写入文件\n",
    "output=pd.DataFrame({'Id':test_df.id,'Predicted':test_pred})\n",
    "output.to_csv('data/results.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "tryy = np.load('./data/bertf3(5).npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0097396 , -0.07622716,  0.05304861, ...,  0.52224571,\n",
       "         0.26489231,  1.        ],\n",
       "       [-0.52637929, -0.13064612, -0.28737295, ...,  0.21315193,\n",
       "         0.59075469,  1.        ],\n",
       "       [-0.00975796, -0.21178283,  0.02980006, ...,  0.1959189 ,\n",
       "         0.34668219,  1.        ],\n",
       "       ...,\n",
       "       [-0.11315919, -0.15480247, -0.49121901, ...,  0.3148703 ,\n",
       "         0.42239293,         nan],\n",
       "       [ 0.04391461, -0.0982058 , -0.06216805, ...,  0.36087343,\n",
       "         0.10998979,         nan],\n",
       "       [ 0.10511701, -0.05473848,  0.08738177, ...,  0.47462544,\n",
       "         0.28318512,         nan]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tryy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35208, 769)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tryy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000.0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = tryy[:,768][:24000]\n",
    "sum(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0097396 , -0.07622716,  0.05304861, ..., -0.14644121,\n",
       "         0.52224571,  0.26489231],\n",
       "       [-0.52637929, -0.13064612, -0.28737295, ...,  0.17828295,\n",
       "         0.21315193,  0.59075469],\n",
       "       [-0.00975796, -0.21178283,  0.02980006, ..., -0.11723166,\n",
       "         0.1959189 ,  0.34668219],\n",
       "       ...,\n",
       "       [ 0.18401402, -0.33296385,  0.01902012, ...,  0.00902978,\n",
       "         0.54764074,  0.32343212],\n",
       "       [-0.23170309, -0.17729409, -0.13758963, ..., -0.22204168,\n",
       "         0.32135811,  0.36318263],\n",
       "       [ 0.12418755, -0.10782202,  0.02178431, ..., -0.09299452,\n",
       "         0.42526135,  0.15571694]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tryy[:,0:768][:24000]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "  \n",
    "features = normalize(features, axis = 0)\n",
    "\n",
    "a = pd.DataFrame(features)\n",
    "for c in a[:1]:\n",
    "    a[c] = pd.cut(a[c], bins = 10, labels = False) / 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6, 0.6, 0.6, ..., 0.4, 0.5, 0.4],\n",
       "       [0.2, 0.5, 0.3, ..., 0.7, 0.2, 0.7],\n",
       "       [0.6, 0.4, 0.6, ..., 0.4, 0.2, 0.5],\n",
       "       ...,\n",
       "       [0.8, 0.4, 0.5, ..., 0.6, 0.6, 0.5],\n",
       "       [0.7, 0.5, 0.4, ..., 0.7, 0.4, 0.4],\n",
       "       [0.6, 0.6, 0.3, ..., 0.6, 0.4, 0.4]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state = 2020)\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.6792708333333334\n",
      "test score: 0.6402083333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"train score:\", lr_clf.score(train_features, train_labels))\n",
    "\n",
    "pred = lr_clf.predict(test_features)\n",
    "print(\"test score:\", lr_clf.score(test_features, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T =  0\n",
      "error: 0.3943750000000362\n",
      "sum of sample_weight: 0.7887500000000881\n",
      "done in 1.381310s\n",
      "T =  1\n",
      "error: 0.4479989009532351\n",
      "sum of sample_weight: 0.8959978019064609\n",
      "done in 1.396410s\n",
      "T =  2\n",
      "error: 0.4336594281401815\n",
      "sum of sample_weight: 0.8673188562803441\n",
      "done in 1.456425s\n",
      "T =  3\n",
      "error: 0.4785017771143575\n",
      "sum of sample_weight: 0.9570035542285301\n",
      "done in 1.313404s\n",
      "T =  4\n",
      "error: 0.4297719413482023\n",
      "sum of sample_weight: 0.8595438826964671\n",
      "done in 1.354405s\n",
      "done in 6.903955s\n",
      "done in 3.196664s\n",
      "[0.23149543 0.66316066 0.4535494  ... 0.23149543 1.         0.66316066]\n",
      "train AUC score: 0.673690493370761\n",
      "test AUC score: 0.6475978749631071\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split # 划分数据集函数(用来帮助随机采样)\n",
    "# from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "# from sklearn.svm import LinearSVR\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time\n",
    "#bagging + bert + logistic regression\n",
    "t0 = time()\n",
    "model = AdaBoost(ml = 'LogisticRegression')\n",
    "model.fit(train_features, train_labels)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "pred = model.predict(train_features)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(pred)\n",
    "print(\"train AUC score:\", roc_auc_score(train_labels, pred))\n",
    "\n",
    "testpred = model.predict(test_features)\n",
    "print(\"test AUC score:\", roc_auc_score(test_labels, testpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.8992708333333334\n",
      "test score: 0.6370833333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(train_features, train_labels)\n",
    "print(\"train score:\", clf.score(train_features, train_labels))\n",
    "\n",
    "pred = clf.predict(test_features)\n",
    "print(\"test score:\", clf.score(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9997395833333333\n",
      "test score: 0.5883333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(train_features,train_labels)\n",
    "print(\"train score:\", clf.score(train_features, train_labels))\n",
    "\n",
    "pred = clf.predict(test_features)\n",
    "print(\"test score:\", clf.score(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# #预处理过，只有20词的content\n",
    "train_df = pd.read_csv(r'data/train1.csv', sep=',')\n",
    "test_df = pd.read_csv(r'data/test1.csv', sep=',')\n",
    "train_df.head()\n",
    "\n",
    "#抄作业bert\n",
    "\n",
    "import pandas as pd\n",
    "import codecs, gc\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    " \n",
    "maxlen = 100  #设置序列长度为120，要保证序列长度不超过512\n",
    " \n",
    "#预训练好的模型\n",
    "config_path = 'uncased_L-12_H-768_A-12/bert_config.json'\n",
    "checkpoint_path = 'uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "dict_path = 'uncased_L-12_H-768_A-12/vocab.txt'\n",
    " \n",
    "#将词表中的词编号转换为字典\n",
    "token_dict = {}\n",
    "with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)\n",
    " \n",
    "# 重写tokenizer        \n",
    "class OurTokenizer(Tokenizer):\n",
    "    def _tokenize(self, text):\n",
    "        R = []\n",
    "        for c in text:\n",
    "            if c in self._token_dict:\n",
    "                R.append(c)\n",
    "            elif self._is_space(c):\n",
    "                R.append('[unused1]')  # 用[unused1]来表示空格类字符\n",
    "            else:\n",
    "                R.append('[UNK]')  # 不在列表的字符用[UNK]表示\n",
    "        return R\n",
    "    \n",
    "tokenizer = OurTokenizer(token_dict)\n",
    " \n",
    "#让每条文本的长度相同，用0填充\n",
    "def seq_padding(X, padding=0):\n",
    "    L = [len(x) for x in X]\n",
    "    ML = max(L)\n",
    "    return np.array([\n",
    "        np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x for x in X\n",
    "    ])\n",
    " \n",
    "#data_generator只是一种为了节约内存的数据方式\n",
    "class data_generator:\n",
    "    def __init__(self, data, batch_size=32, shuffle=True):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.steps = len(self.data) // self.batch_size\n",
    "        if len(self.data) % self.batch_size != 0:\n",
    "            self.steps += 1\n",
    " \n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    " \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            idxs = list(range(len(self.data)))\n",
    " \n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(idxs)\n",
    " \n",
    "            X1, X2, Y = [], [], []\n",
    "            for i in idxs:\n",
    "                d = self.data[i]\n",
    "                text = d[0][:maxlen]\n",
    "                x1, x2 = tokenizer.encode(first=text)\n",
    "                y = d[1]\n",
    "                X1.append(x1)\n",
    "                X2.append(x2)\n",
    "                Y.append([y])\n",
    "                if len(X1) == self.batch_size or i == idxs[-1]:\n",
    "                    X1 = seq_padding(X1)\n",
    "                    X2 = seq_padding(X2)\n",
    "                    Y = seq_padding(Y)\n",
    "                    yield [X1, X2], Y[:, 0, :]\n",
    "                    [X1, X2, Y] = [], [], []\n",
    " \n",
    "# 计算top-k正确率,当预测值的前k个值中存在目标类别即认为预测正确                 \n",
    "def acc_top1(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=1)\n",
    " \n",
    "#bert模型设置\n",
    "def build_bert(nclass):\n",
    "    bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, seq_len=None)  #加载预训练模型\n",
    " \n",
    "    for l in bert_model.layers:\n",
    "        l.trainable = True\n",
    " \n",
    "    x1_in = Input(shape=(None,))\n",
    "    x2_in = Input(shape=(None,))\n",
    " \n",
    "    x = bert_model([x1_in, x2_in])\n",
    "    x = Lambda(lambda x: x[:, 0])(x) # 取出[CLS]对应的向量用来做分类\n",
    "    p = Dense(nclass, activation='softmax')(x)\n",
    " \n",
    "    model = Model([x1_in, x2_in], p)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(1e-5),    #用足够小的学习率\n",
    "                  metrics=['accuracy', acc_top1])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "#训练数据、测试数据和标签转化为模型输入格式\n",
    "DATA_LIST = []\n",
    "for data_row in train_df.iloc[:].itertuples():\n",
    "    DATA_LIST.append((data_row.content, to_categorical(data_row.label, 2)))\n",
    "DATA_LIST = np.array(DATA_LIST)\n",
    " \n",
    "DATA_LIST_TEST = []\n",
    "for data_row in test_df.iloc[:].itertuples():\n",
    "    DATA_LIST_TEST.append((data_row.content, to_categorical(0, 2)))\n",
    "DATA_LIST_TEST = np.array(DATA_LIST_TEST)\n",
    "\n",
    "def run_cv(nfold, data, data_labels, data_test):\n",
    "    kf = KFold(n_splits=nfold, shuffle=True, random_state=520).split(data)\n",
    "    train_model_pred = np.zeros((len(data), 2))\n",
    "    test_model_pred = np.zeros((len(data_test), 2))\n",
    " \n",
    "    for i, (train_fold, test_fold) in enumerate(kf):\n",
    "        X_train, X_valid, = data[train_fold, :], data[test_fold, :]\n",
    " \n",
    "        model = build_bert(2)\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=3)   #早停法，防止过拟合\n",
    "        plateau = ReduceLROnPlateau(monitor=\"val_acc\", verbose=1, mode='max', factor=0.5, patience=2) #当评价指标不在提升时，减少学习率\n",
    "        checkpoint = ModelCheckpoint('./bert_dump/' + str(i) + '.hdf5', monitor='val_acc',verbose=2, save_best_only=True, mode='max', save_weights_only=True) #保存最好的模型\n",
    " \n",
    "        train_D = data_generator(X_train, shuffle=True)\n",
    "        valid_D = data_generator(X_valid, shuffle=True)\n",
    "        test_D = data_generator(data_test, shuffle=False)\n",
    "        #模型训练\n",
    "        model.fit(\n",
    "            train_D.__iter__(),\n",
    "            steps_per_epoch=5,\n",
    "            epochs=2,\n",
    "            validation_data=valid_D.__iter__(),\n",
    "            validation_steps=len(valid_D),\n",
    "            callbacks=[early_stopping, plateau, checkpoint],\n",
    "        )\n",
    " \n",
    "        # model.load_weights('./bert_dump/' + str(i) + '.hdf5')\n",
    " \n",
    "        # return model\n",
    "        train_model_pred[test_fold, :] = model.predict(valid_D.__iter__(), steps=len(valid_D), verbose=1)\n",
    "        test_model_pred += model.predict(test_D.__iter__(), steps=len(test_D), verbose=1)\n",
    " \n",
    "        del model\n",
    "        gc.collect()   #清理内存\n",
    "        K.clear_session()   #clear_session就是清除一个session\n",
    "        # break\n",
    " \n",
    "    return train_model_pred, test_model_pred\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_3 (Functional)       (None, None, 768)    108891648   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 768)          0           functional_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            1538        lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 108,893,186\n",
      "Trainable params: 108,893,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5948 - accuracy: 0.7500 - acc_top1: 0.7500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-4ec225e4b5ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#n折交叉验证\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_model_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_model_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDATA_LIST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDATA_LIST_TEST\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_model_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-162-9124273da5b5>\u001b[0m in \u001b[0;36mrun_cv\u001b[1;34m(nfold, data, data_labels, data_test)\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplateau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m         )\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m               return_dict=True)\n\u001b[0m\u001b[0;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TraceContext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#n折交叉验证\n",
    "train_model_pred, test_model_pred = run_cv(2, DATA_LIST, None, DATA_LIST_TEST)\n",
    " \n",
    "test_pred = [np.argmax(x) for x in test_model_pred]\n",
    " \n",
    "#将测试集预测结果写入文件\n",
    "output=pd.DataFrame({'Id':test_df.id,'Predicted':test_pred})\n",
    "# output.to_csv('data/results.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-180-111212ea31fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_pred' is not defined"
     ]
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
